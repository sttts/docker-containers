#!/bin/bash

set -ex

# Copyright 2013-2015 Jérôme Petazzoni, Johan Haleby, lalyos, James Harris,
#                     Michael Elsdörfer, Tony Hesjevik, Esben Haabendal,
#                     Michael A. Smith, Stefan Schimanski, Karl Isenberg
# Original source: https://github.com/jpetazzo/dind
# Modified to add docker network reservations.

: {LOG:=stdio}

# Ensure that all nodes in /dev/mapper correspond to mapped devices currently loaded by the device-mapper kernel driver
dmsetup mknodes

# apparmor sucks and Docker needs to know that it's in a container (c) @tianon
export container=docker

# as of docker 1.8, cgroups will be mounted in the container
if ! mountpoint -q /sys/fs/cgroup; then

	# First, make sure that cgroups are mounted correctly.
	CGROUP=/cgroup

	mkdir -p "$CGROUP"

	if ! mountpoint -q "$CGROUP"; then
		mount -n -t tmpfs -o uid=0,gid=0,mode=0755 cgroup $CGROUP || {
			echo >&2 'Could not make a tmpfs mount. Did you use --privileged?'
			exit 1
		}
	fi

	# Mount the cgroup hierarchies exactly as they are in the parent system.
	for HIER in $(cut -d: -f2 /proc/1/cgroup); do

		# The following sections address a bug which manifests itself
		# by a cryptic "lxc-start: no ns_cgroup option specified" when
		# trying to start containers within a container.
		# The bug seems to appear when the cgroup hierarchies are not
		# mounted on the exact same directories in the host, and in the
		# container.

		SUBSYSTEMS="${HIER%name=*}"

		# If cgroup hierarchy is named(mounted with "-o name=foo") we
		# need to mount it in $CGROUP/foo to create exect same
		# directoryes as on host. Else we need to mount it as is e.g.
		# "subsys1,subsys2" if it has two subsystems

		# Named, control-less cgroups are mounted with "-o name=foo"
		# (and appear as such under /proc/<pid>/cgroup) but are usually
		# mounted on a directory named "foo" (without the "name=" prefix).
		# Systemd and OpenRC (and possibly others) both create such a
		# cgroup. So just mount them on directory $CGROUP/foo.

		OHIER=$HIER
		HIER="${HIER#*name=}"

		mkdir -p "$CGROUP/$HIER"

		if ! mountpoint -q "$CGROUP/$HIER"; then
			mount -n -t cgroup -o "$OHIER" cgroup "$CGROUP/$HIER"
		fi

		# Likewise, on at least one system, it has been reported that
		# systemd would mount the CPU and CPU accounting controllers
		# (respectively "cpu" and "cpuacct") with "-o cpuacct,cpu"
		# but on a directory called "cpu,cpuacct" (note the inversion
		# in the order of the groups). This tries to work around it.

		if [ "$HIER" = 'cpuacct,cpu' ]; then
			ln -s "$HIER" "$CGROUP/cpu,cpuacct"
		fi

		# If hierarchy has multiple subsystems, in /proc/<pid>/cgroup
		# we will see ":subsys1,subsys2,subsys3,name=foo:" substring,
		# we need to mount it to "$CGROUP/foo" and if there were no
		# name to "$CGROUP/subsys1,subsys2,subsys3", so we must create
		# symlinks for docker daemon to find these subsystems:
		# ln -s $CGROUP/foo $CGROUP/subsys1
		# ln -s $CGROUP/subsys1,subsys2,subsys3 $CGROUP/subsys1

		if [ "$SUBSYSTEMS" != "${SUBSYSTEMS//,/ }" ]; then
			SUBSYSTEMS="${SUBSYSTEMS//,/ }"
			for SUBSYS in $SUBSYSTEMS
			do
				ln -s "$CGROUP/$HIER" "$CGROUP/$SUBSYS"
			done
		fi
	done
fi

if [ -d /sys/kernel/security ] && ! mountpoint -q /sys/kernel/security; then
	mount -t securityfs none /sys/kernel/security || {
		echo >&2 'Could not mount /sys/kernel/security.'
		echo >&2 'AppArmor detection and -privileged mode might break.'
	}
fi

# Note: as I write those lines, the LXC userland tools cannot setup
# a "sub-container" properly if the "devices" cgroup is not in its
# own hierarchy. Let's detect this and issue a warning.
if ! grep -q :devices: /proc/1/cgroup; then
	echo >&2 'WARNING: the "devices" cgroup should be in its own hierarchy.'
fi
if ! grep -qw devices /proc/1/cgroup; then
	echo >&2 'WARNING: it looks like the "devices" cgroup is not mounted.'
fi

# Mount /tmp (conditionally)
if ! mountpoint -q /tmp; then
	mount -t tmpfs none /tmp
fi

# find supported filesystem to use for docker image mounts
if grep -q overlay /proc/filesystems; then
    STORAGE_FS=overlay
elif grep -q aufs /proc/filesystems; then
    STORAGE_FS=aufs
else
    echo "No supported filesystem found (aufs, overlay)"
    exit 1
fi

# find filesystem below /var/lib/docker
STORAGE_DIR="/var/lib/docker"
mkdir -p "${STORAGE_DIR}"
STORAGE_DIR_FS=$(df -PTh "${STORAGE_DIR}" | awk '{print $2}' | tail -1)

# Unless using overlay over overlay, create an ext3 loop device as an intermediary layer.
# The max size of the loop device is $VAR_LIB_DOCKER_SIZE in GB (default=5).
if [ "${STORAGE_DIR_FS}" != "overlay" ] || [ "${STORAGE_FS}" != "overlay" ]; then
    STORAGE_FILE="/data/docker"
    VAR_LIB_DOCKER_SIZE=${VAR_LIB_DOCKER_SIZE:-5}
    mkdir -p "$(dirname "${STORAGE_FILE}")"
    if [ ! -f "${STORAGE_FILE}" ]; then
        dd if=/dev/zero of="${STORAGE_FILE}" bs=1G seek=${VAR_LIB_DOCKER_SIZE} count=0
        echo y | mkfs.ext3 "${STORAGE_FILE}"
    fi
    mount -o loop "${STORAGE_FILE}" "${STORAGE_DIR}"
fi

# If a pidfile is still around (for example after a container restart),
# delete it so that docker can start.
rm -rf /var/run/docker.pid

# create docker0 bridge manually and attach it to the veth interface eth0
brctl addbr docker0
brctl addif docker0 eth0
ip link set docker0 up

# move ip to the bridge and restore routing via the old gateway
IP_CIDR=$(ip addr show eth0 | grep -w inet | awk '{ print $2; }')
IP=$(echo $IP_CIDR | sed 's,/.*,,')
NETWORK_SIZE=$(echo $IP_CIDR | sed 's,.*/,,')
DEFAULT_ROUTE=$(ip route | grep default | sed 's/eth0/docker0/')

ip addr del $IP_CIDR dev eth0
ip addr add $IP_CIDR dev docker0
ip route add $DEFAULT_ROUTE


# compute a network for the containers to live in
# by adding DOCKER_NETWORK_OFFSET to the current IP and cutting off
# non-network bits according to DOCKER_NETWORK_SIZE
DOCKER_NETWORK_SIZE=${DOCKER_NETWORK_SIZE:-24}
DOCKER_NETWORK_OFFSET=${DOCKER_NETWORK_OFFSET:-0.0.1.0}
NETWORK=$(ip route | grep docker0 | grep -v default | sed 's,/.*,,')

IFS=. read -r i1 i2 i3 i4 <<< $IP
IFS=. read -r n1 n2 n3 n4 <<< $NETWORK
IFS=. read -r o1 o2 o3 o4 <<< $DOCKER_NETWORK_OFFSET
IFS=. read -r w1 w2 w3 w4 <<< $(ipcalc $IP_CIDR | grep Wildcard | awk '{print $2;}')

IP_PLUS_OFFSET=$(printf "%d.%d.%d.%d\n" \
    "$(( n1 + ((i1 - n1 + o1) & w1) ))" \
    "$(( n2 + ((i2 - n2 + o2) & w2) ))" \
    "$(( n3 + ((i3 - n3 + o3) & w3) ))" \
    "$(( n4 + ((i4 - n4 + o4) & w4) ))")

FIXED_CIDR=$(ipcalc $IP_PLUS_OFFSET/$DOCKER_NETWORK_SIZE | grep Network | awk '{print $2;}')
echo "Using network $FIXED_CIDR for docker containers"

# stop docker daemon on shutdown to avoid loopback leaks
trap "service docker stop" EXIT

# let docker reuse the given IP. If you run more than one dind slave, add
# --fixed-cidr=a.b.c.d/24 to DOCKER_DAEMON_ARGS with disjunct networks.
DOCKER_DAEMON_ARGS="${DOCKER_DAEMON_ARGS} --bip=${IP_CIDR} --fixed-cidr=${FIXED_CIDR} --storage-driver=${STORAGE_FS} -D"

# start docker daemon
if [ "$LOG" == "file" ]; then
	docker daemon ${DOCKER_DAEMON_ARGS} &>/var/log/docker.log &
else
	docker daemon ${DOCKER_DAEMON_ARGS} &
fi
(( timeout = 60 + SECONDS ))
until docker info >/dev/null 2>&1
do
	if (( SECONDS >= timeout )); then
		echo 'Timed out trying to connect to internal docker host.' >&2
		exit 1
	fi
	sleep 1
done
[[ $1 ]] && exec "$@"
exec bash --login
